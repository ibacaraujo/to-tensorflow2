{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beginning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibacaraujo/to-tensorflow2/blob/master/beginning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXDtut9Iuc86",
        "colab_type": "text"
      },
      "source": [
        "# The beginner notebook. Let's begin!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBLTrr4NukX8",
        "colab_type": "text"
      },
      "source": [
        "Download and install TensorFlow 2.0 and then import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llm0RtZauUaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "758b5103-2db1-4082-cb45-e8b64b085ef7"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow 2.0\n",
        "!pip install tensorflow==2.0.0-beta1\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 53.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 37.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta1) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (0.15.5)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKYWOD_GvBMx",
        "colab_type": "text"
      },
      "source": [
        "Load the dataset. Let's use MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHW30TWbu9S4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "605dd4d3-bf61-4c9b-b185-e6c0dd59b623"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# convert the samples from integer to float\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD9TFND4vVZC",
        "colab_type": "text"
      },
      "source": [
        "Build the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbd9KmGVvYds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stacking layers and selecting an optimizer and a loss function for training\n",
        "\n",
        "# Stacking layers\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Selecting for compilation. We also pass the metrics\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNyVwty7v_tJ",
        "colab_type": "text"
      },
      "source": [
        "Let's train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr4NhcgdwCtp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "297f06e9-5401-4ed9-f990-5ab9df12e042"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=5) # training, define the number of epochs\n",
        "\n",
        "model.evaluate(x_test, y_test) # evaluating"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0801 10:36:27.092461 139722593466240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3021 - accuracy: 0.9117\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1463 - accuracy: 0.9564\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.1098 - accuracy: 0.9669\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0899 - accuracy: 0.9723\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0782 - accuracy: 0.9757\n",
            "10000/10000 [==============================] - 0s 34us/sample - loss: 0.0782 - accuracy: 0.9760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07823320365836844, 0.976]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZA7uksewT_e",
        "colab_type": "text"
      },
      "source": [
        "Trained to ~98% accuracy on MNIST. We are going to learn more.\n",
        "\n",
        "Let me explore. Let me see another datasets that are provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxIJHwV8wrN0",
        "colab_type": "text"
      },
      "source": [
        "CIFAR10, classical dataset. Let's explore with it. Let's extend, let's expand this notebook.\n",
        "\n",
        "Let's build a model for CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWZWFQHfwpm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "625f0423-5530-49ab-d03c-1aeeba37b0c4"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "# from int to float\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUF4G6YaxLqh",
        "colab_type": "text"
      },
      "source": [
        "Let me explore the dataset to build the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXAQ0WOcxQ2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43047d7c-4851-41d2-adea-ea0b74563d6e"
      },
      "source": [
        "type(x_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnjCAg7exVwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06641388-d9f5-478b-89eb-870d566e7bfb"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdbrahubxaTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "467b99df-8d31-4f26-ccf4-b5712b655e62"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnS3Fjfzxfft",
        "colab_type": "text"
      },
      "source": [
        "Just know the input shape. Just that is good, based on the beginner approach.\n",
        "\n",
        "Build the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyYT9xCdxjTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_cifar = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cifar.compile(optimizer='adam',\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r03jy6tyK-z",
        "colab_type": "text"
      },
      "source": [
        "Train on CIFAR10 train set and evaluate on CIFAR10 test set!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czkkyd9EyN9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "765107a4-d34f-4bc4-9028-74e45f226ad9"
      },
      "source": [
        "model_cifar.fit(x_train, y_train, epochs=5) # same model, same number of epochs\n",
        "\n",
        "model_cifar.evaluate(x_test, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 6s 112us/sample - loss: 2.0358 - accuracy: 0.2398\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 5s 109us/sample - loss: 1.9468 - accuracy: 0.2796\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 5s 108us/sample - loss: 1.9271 - accuracy: 0.2866\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 5s 107us/sample - loss: 1.9122 - accuracy: 0.2919\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 5s 107us/sample - loss: 1.9039 - accuracy: 0.2988\n",
            "10000/10000 [==============================] - 1s 55us/sample - loss: 1.8013 - accuracy: 0.3524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8013079940795897, 0.3524]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETUHUI9Qyb1U",
        "colab_type": "text"
      },
      "source": [
        "35% accuracy. Low, man. Let me compile again, and train with a higher number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K28CcpmRyg92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1636a676-255a-4fd3-84fc-6840d503a805"
      },
      "source": [
        "model_cifar.fit(x_train, y_train, epochs=30) # same model, 30 epochs\n",
        "\n",
        "model_cifar.evaluate(x_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 6s 111us/sample - loss: 2.0403 - accuracy: 0.2355\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 5s 108us/sample - loss: 1.9431 - accuracy: 0.2699\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 5s 107us/sample - loss: 1.9194 - accuracy: 0.2807\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 5s 109us/sample - loss: 1.9108 - accuracy: 0.2867\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 5s 109us/sample - loss: 1.8996 - accuracy: 0.2907\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 5s 107us/sample - loss: 1.8901 - accuracy: 0.2928\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 5s 107us/sample - loss: 1.8852 - accuracy: 0.2992\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 5s 108us/sample - loss: 1.8765 - accuracy: 0.3043\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 5s 107us/sample - loss: 1.8671 - accuracy: 0.3112\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 5s 110us/sample - loss: 1.8599 - accuracy: 0.3157\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 6s 112us/sample - loss: 1.8521 - accuracy: 0.3187\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 6s 112us/sample - loss: 1.8492 - accuracy: 0.3211\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 6s 112us/sample - loss: 1.8437 - accuracy: 0.3214\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 6s 116us/sample - loss: 1.8390 - accuracy: 0.3240\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 6s 118us/sample - loss: 1.8320 - accuracy: 0.3276\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 6s 114us/sample - loss: 1.8331 - accuracy: 0.3277\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 5s 108us/sample - loss: 1.8304 - accuracy: 0.3292\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 5s 109us/sample - loss: 1.8218 - accuracy: 0.3319\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 5s 109us/sample - loss: 1.8232 - accuracy: 0.3311\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 5s 108us/sample - loss: 1.8186 - accuracy: 0.3313\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 5s 107us/sample - loss: 1.8236 - accuracy: 0.3284\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 5s 110us/sample - loss: 1.8213 - accuracy: 0.3304\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 6s 112us/sample - loss: 1.8182 - accuracy: 0.3307\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 6s 112us/sample - loss: 1.8146 - accuracy: 0.3322\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 6s 112us/sample - loss: 1.8129 - accuracy: 0.3367\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 6s 115us/sample - loss: 1.8175 - accuracy: 0.3325\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 6s 118us/sample - loss: 1.8073 - accuracy: 0.3380\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 6s 115us/sample - loss: 1.8120 - accuracy: 0.3347\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 6s 118us/sample - loss: 1.8082 - accuracy: 0.3362\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 6s 120us/sample - loss: 1.8064 - accuracy: 0.3373\n",
            "10000/10000 [==============================] - 1s 60us/sample - loss: 1.7177 - accuracy: 0.3828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7177017416000366, 0.3828]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dguV04r2zOxw",
        "colab_type": "text"
      },
      "source": [
        "An increase of 3%. Good. Interesting, learn more providing more epochs.\n",
        "\n",
        "Let me build model with more capacity. Two more hidden layers, so more deep. Besides, wider.\n",
        "\n",
        "Look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "637niH-QzOZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2_cifar = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model2_cifar.compile(optimizer='adam',\n",
        "                     loss='sparse_categorical_crossentropy',\n",
        "                     metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edvId6Adz8CI",
        "colab_type": "text"
      },
      "source": [
        "Let's test and compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmjIDHioz9o6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "3cd979d2-581a-405d-ad06-47e7b8c9a11a"
      },
      "source": [
        "model2_cifar.fit(x_train, y_train, epochs=5) # deeper and wider model, 5 epochs\n",
        "\n",
        "model2_cifar.evaluate(x_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 18s 363us/sample - loss: 2.0357 - accuracy: 0.2409\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 18s 363us/sample - loss: 1.9096 - accuracy: 0.2945\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 18s 369us/sample - loss: 1.8845 - accuracy: 0.3059\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 19s 388us/sample - loss: 1.8584 - accuracy: 0.3180\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 19s 376us/sample - loss: 1.8451 - accuracy: 0.3251\n",
            "10000/10000 [==============================] - 1s 130us/sample - loss: 1.7592 - accuracy: 0.3609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7591705654144287, 0.3609]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9nDAk4w0k-J",
        "colab_type": "text"
      },
      "source": [
        "1% increase compared with the first model. Let's see with 30 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzjKEZB00pmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60fdf354-378d-48f1-9253-9dd133c1df85"
      },
      "source": [
        "model2_cifar.fit(x_train, y_train, epochs=30)\n",
        "\n",
        "model2_cifar.evaluate(x_test, y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 18s 350us/sample - loss: 2.0277 - accuracy: 0.2480\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 17s 341us/sample - loss: 1.8926 - accuracy: 0.3038\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 17s 339us/sample - loss: 1.8479 - accuracy: 0.3271\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 17s 346us/sample - loss: 1.8154 - accuracy: 0.3393\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 17s 339us/sample - loss: 1.7938 - accuracy: 0.3494\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 17s 341us/sample - loss: 1.7788 - accuracy: 0.3540\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 17s 344us/sample - loss: 1.7566 - accuracy: 0.3626\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 17s 342us/sample - loss: 1.7510 - accuracy: 0.3644\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 17s 340us/sample - loss: 1.7383 - accuracy: 0.3682\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 17s 341us/sample - loss: 1.7300 - accuracy: 0.3733\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 17s 335us/sample - loss: 1.7181 - accuracy: 0.3787\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 17s 343us/sample - loss: 1.7134 - accuracy: 0.3799\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 17s 335us/sample - loss: 1.7165 - accuracy: 0.3789\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 17s 343us/sample - loss: 1.7084 - accuracy: 0.3816\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 17s 338us/sample - loss: 1.7029 - accuracy: 0.3860\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 17s 339us/sample - loss: 1.6985 - accuracy: 0.3859\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 17s 340us/sample - loss: 1.6974 - accuracy: 0.3853\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 17s 340us/sample - loss: 1.6927 - accuracy: 0.3887\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 17s 344us/sample - loss: 1.6918 - accuracy: 0.3893\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 17s 339us/sample - loss: 1.6853 - accuracy: 0.3894\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 17s 343us/sample - loss: 1.6796 - accuracy: 0.3948\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 17s 342us/sample - loss: 1.6735 - accuracy: 0.3941\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 17s 341us/sample - loss: 1.6793 - accuracy: 0.3946\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 17s 339us/sample - loss: 1.6767 - accuracy: 0.3938\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 17s 340us/sample - loss: 1.6737 - accuracy: 0.3951\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 17s 340us/sample - loss: 1.6694 - accuracy: 0.4000\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 17s 341us/sample - loss: 1.6654 - accuracy: 0.3979\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 17s 349us/sample - loss: 1.6677 - accuracy: 0.3987\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 17s 344us/sample - loss: 1.6641 - accuracy: 0.3989\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 18s 352us/sample - loss: 1.6638 - accuracy: 0.4012\n",
            "10000/10000 [==============================] - 1s 119us/sample - loss: 1.5950 - accuracy: 0.4355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5950096361160278, 0.4355]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN77mvEi21OY",
        "colab_type": "text"
      },
      "source": [
        "5% increase gain regarding the first model for CIFAR10. Interesting to see the power of epochs in practice. You provide more capacity, and with more epochs, the gains are better."
      ]
    }
  ]
}