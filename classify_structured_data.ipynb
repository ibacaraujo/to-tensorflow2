{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify_structured_data",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibacaraujo/to-tensorflow2/blob/master/classify_structured_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjyO5ExUHfxi",
        "colab_type": "text"
      },
      "source": [
        "# Classify Structured Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLHGPA3kGkHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d70ddf38-5649-4239-ab18-0ce945994e85"
      },
      "source": [
        "!pip install sklearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHIWqY2oG-yR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "effd7544-bb78-4aad-ce13-8f3aea5900e8"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "!pip install -q tensorflow==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 87.9MB 1.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 40.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 32.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fxGXftaHir9",
        "colab_type": "text"
      },
      "source": [
        "## Create dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMduMuzpHlLR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9d3af932-3c37-48e4-d84c-d1b02e539659"
      },
      "source": [
        "URL = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
        "dataframe = pd.read_csv(URL)\n",
        "dataframe.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>fixed</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>160</td>\n",
              "      <td>286</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>reversible</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  ...  oldpeak  slope  ca        thal  target\n",
              "0   63    1   1       145   233  ...      2.3      3   0       fixed       0\n",
              "1   67    1   4       160   286  ...      1.5      2   3      normal       1\n",
              "2   67    1   4       120   229  ...      2.6      2   2  reversible       0\n",
              "3   37    1   3       130   250  ...      3.5      3   0      normal       0\n",
              "4   41    0   2       130   204  ...      1.4      1   0      normal       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7klEAWaEHvn-",
        "colab_type": "text"
      },
      "source": [
        "## Split the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rarRI4sEHw5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "900d9db0-3932-4328-d2e4-684905daea49"
      },
      "source": [
        "train, test = train_test_split(dataframe, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'val examples')\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "193 train examples\n",
            "49 val examples\n",
            "61 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3s6lRdHIBm-",
        "colab_type": "text"
      },
      "source": [
        "## Create an input pipeline using tf.data\n",
        "\n",
        "tf.data to wrap the dataframe, so we will be able to use feature columns as a bridge to map from the columns in the Pandas dataframe to features used to train the model.\n",
        "\n",
        "If it were a large CSV file, in a way that does not fit in memory, we would use tf.data to read it from disk directly. Interesting! To learn!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tygw4g0IEvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('target')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNaZwC4PI8jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 5 # small batch for demonstration purposes\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sjte-qMJLmq",
        "colab_type": "text"
      },
      "source": [
        "## Understand the input pipeline\n",
        "\n",
        "Let's see the format of the input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqr4e5RrJN9v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "50726147-c303-497d-ad62-e681038445ca"
      },
      "source": [
        "for feature_batch, label_batch in train_ds.take(1):\n",
        "  print('Every feature:', list(feature_batch.keys()))\n",
        "  print('A batch of ages:', feature_batch['age'])\n",
        "  print('A batch of targets:', label_batch)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Every feature: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
            "A batch of ages: tf.Tensor([58 55 63 57 45], shape=(5,), dtype=int32)\n",
            "A batch of targets: tf.Tensor([0 0 1 0 0], shape=(5,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkL3Yl2BJqbq",
        "colab_type": "text"
      },
      "source": [
        "A dictionary with keys being the feature names and columns as tf.Tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39ysyCcgKAZi",
        "colab_type": "text"
      },
      "source": [
        "## Demonstrate several types of feature column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gFm_fWfKC7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will use this batch to demonstrate several types of feature columns\n",
        "example_batch = next(iter(train_ds))[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo_XmTenKQkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility method to create a feature column and to transform a batch of data\n",
        "def demo(feature_column):\n",
        "  feature_layer = layers.DenseFeatures(feature_column)\n",
        "  print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3imIf2pjKscY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "888b23fa-e3a5-44fc-aa8c-96a116f214db"
      },
      "source": [
        "age = feature_column.numeric_column(\"age\")\n",
        "demo(age)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[58.]\n",
            " [55.]\n",
            " [63.]\n",
            " [57.]\n",
            " [45.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2HBZZ1uLjCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2fe66169-9ab0-4666-b196-52132aa67f4b"
      },
      "source": [
        "age_buckets = feature_column.bucketized_column(age, \n",
        "  boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
        "demo(age_buckets)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x1FknDjL_Kh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "31c1e367-3913-4d40-d956-70e6a4dae208"
      },
      "source": [
        "thal = feature_column.categorical_column_with_vocabulary_list(\n",
        "    'thal', ['fixed', 'normal', 'reversible'])\n",
        "thal_one_hot = feature_column.indicator_column(thal)\n",
        "demo(thal_one_hot)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0808 03:06:27.011060 140159448045440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0808 03:06:27.023420 140159448045440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4215: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "W0808 03:06:27.025430 140159448045440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbOLTYkPMVUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "15bd2c7f-f58e-4a36-f72f-dcb29556645c"
      },
      "source": [
        "# embedding when the number of categories is high\n",
        "thal_embedding = feature_column.embedding_column(thal, dimension=8)\n",
        "demo(thal_embedding)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.32926026  0.6037977   0.0859094  -0.1343561   0.18337654 -0.260106\n",
            "  -0.09752115 -0.32585666]\n",
            " [-0.2929751  -0.55914295 -0.33032867 -0.26798528  0.05934702 -0.19060789\n",
            "  -0.2030002  -0.05641369]\n",
            " [ 0.32926026  0.6037977   0.0859094  -0.1343561   0.18337654 -0.260106\n",
            "  -0.09752115 -0.32585666]\n",
            " [ 0.32926026  0.6037977   0.0859094  -0.1343561   0.18337654 -0.260106\n",
            "  -0.09752115 -0.32585666]\n",
            " [-0.2929751  -0.55914295 -0.33032867 -0.26798528  0.05934702 -0.19060789\n",
            "  -0.2030002  -0.05641369]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp_xYATdNkIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b45eeca3-8d21-4d1f-f952-73196f14bca1"
      },
      "source": [
        "thal_hashed = feature_column.categorical_column_with_hash_bucket(\n",
        "    'thal', hash_bucket_size=1000)\n",
        "demo(feature_column.indicator_column(thal_hashed))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0808 03:17:05.568101 140159448045440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR_STLt7O8nZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ae3d696c-2007-4a1e-ec0c-e89f602bdcfc"
      },
      "source": [
        "cross_feature = feature_column.crossed_column(\n",
        "    [age_buckets, thal], hash_bucket_size=1000)\n",
        "demo(feature_column.indicator_column(cross_feature))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0808 03:18:40.419500 140159448045440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AqOWVG-PVIb",
        "colab_type": "text"
      },
      "source": [
        "## Choose which columns to use\n",
        "\n",
        "Let's use the feature columns to train a model.\n",
        "\n",
        "Key point: if your aim is to build an accurate model, try a larger dataset of your own, and think carefully about which features are the most meaningful to include, and how they should be represented.\n",
        "\n",
        "Great!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6UUhZMoPYBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "# numeric cols\n",
        "for header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']:\n",
        "  feature_columns.append(feature_column.numeric_column(header))\n",
        "  \n",
        "# bucketized cols\n",
        "age_buckets = feature_column.bucketized_column(\n",
        "    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
        "feature_columns.append(age_buckets)\n",
        "\n",
        "# indicator cols\n",
        "thal = feature_column.categorical_column_with_vocabulary_list(\n",
        "  'thal', ['fixed', 'normal', 'reversible'])\n",
        "thal_one_hot = feature_column.indicator_column(thal)\n",
        "feature_columns.append(thal_one_hot)\n",
        "\n",
        "# embedding cols\n",
        "thal_embedding = feature_column.embedding_column(thal, dimension=8)\n",
        "feature_columns.append(thal_embedding)\n",
        "\n",
        "# crossed cols\n",
        "crossed_feature = feature_column.crossed_column(\n",
        "    [age_buckets, thal], hash_bucket_size=1000)\n",
        "crossed_feature = feature_column.indicator_column(crossed_feature)\n",
        "feature_columns.append(crossed_feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veLqiwCBQxLM",
        "colab_type": "text"
      },
      "source": [
        "## Create a feature layer\n",
        "\n",
        "So, we have defined our feature columns, now we will use tf.keras.DenseFeatures layer to input them to our Keras model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV6WohuTQvcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3954d_HRJnS",
        "colab_type": "text"
      },
      "source": [
        "Now, new input pipeline with larger batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Z-7aHHRNG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlvK3qI7RYCW",
        "colab_type": "text"
      },
      "source": [
        "## Create, compile and train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxBmPqgLRaMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ff498e3c-e0bc-4a1d-a7d6-22b7ad56ad6d"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    feature_layer,\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'],\n",
        "             run_eagerly=True)\n",
        "\n",
        "model.fit(train_ds,\n",
        "         validation_data=val_ds,\n",
        "         epochs=5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7/7 [==============================] - 1s 99ms/step - loss: 0.8140 - accuracy: 0.6729 - val_loss: 0.6456 - val_accuracy: 0.6122\n",
            "Epoch 2/5\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5108 - accuracy: 0.7628 - val_loss: 0.5694 - val_accuracy: 0.6939\n",
            "Epoch 3/5\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4330 - accuracy: 0.8160 - val_loss: 0.5498 - val_accuracy: 0.6735\n",
            "Epoch 4/5\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4072 - accuracy: 0.8040 - val_loss: 0.5385 - val_accuracy: 0.6735\n",
            "Epoch 5/5\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4144 - accuracy: 0.8147 - val_loss: 0.5359 - val_accuracy: 0.6735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7920a36be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQM4hwIzSG3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31baca08-bdc3-43cb-b053-ed37609c5d10"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print('Accuracy:', accuracy)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5395 - accuracy: 0.7541\n",
            "Accuracy: 0.75409836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQfo-y8DSPoE",
        "colab_type": "text"
      },
      "source": [
        "Key point: Best results with deep learning with much larger and more complex datasets. When working with a small dataset like this one, we recommend using a decision tree or random forest as a strong baseline. Code to use as a starting point when working with own datasets in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWfFVaXaSiAy",
        "colab_type": "text"
      },
      "source": [
        "Next steps. To work with another dataset! Think carefully about which features to include in the model, and how they should be represented."
      ]
    }
  ]
}